{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fa5801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritu/anaconda3/envs/dnn_for_qubit_mapping/lib/python3.8/site-packages/qiskit/version.py:20: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from qiskit import *\n",
    "from qiskit.providers.ibmq import *\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Flatten\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras.models import Sequential#,Input,Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# from tensorflow import keras\n",
    "# from keras_layer_normalization import BatchNormalization\n",
    "# from keras_layer_normalization import LayerNormalization\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50fa760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataset(df, n_qubits):\n",
    "    df = df.drop_duplicates()\n",
    "    for i in range(n_qubits):\n",
    "        df = df.drop('measure_' + str(i), axis=1)\n",
    "    #Rimozione Features non interessanti\n",
    "    df = df.drop('N_measure', axis = 1)\n",
    "    # remove edges which are not in coupling maps\n",
    "    # connections = ['01','10','12','21','13','31','35','53','45','54','56','65']\n",
    "    connections = []\n",
    "    IBMQ.load_account()\n",
    "    provider = IBMQ.get_provider(hub='ibm-q')\n",
    "    provider.backends(simulator=False)\n",
    "    if n_qubits == 7:\n",
    "        backend = provider.get_backend('ibm_nairobi')\n",
    "        coupling_map = IBMQBackend.configuration(backend).to_dict()['coupling_map']\n",
    "        for tup in coupling_map:\n",
    "            connections.append(str(tup[0])+str(tup[1]))\n",
    "    else:\n",
    "        backend = provider.get_backend('ibm_brisbane')\n",
    "        coupling_map = IBMQBackend.configuration(backend).to_dict()['coupling_map']\n",
    "        for tup in coupling_map:\n",
    "            connections.append(str(tup[0])+str(tup[1]))\n",
    "    print(\"Connections:\",connections)\n",
    "    to_keep = []\n",
    "    for c in connections:\n",
    "        to_keep.append(\"edge_error_\"+c)    \n",
    "        to_keep.append(\"edge_length_\"+c)\n",
    "    to_drop = []\n",
    "    for c in df.columns:\n",
    "        if \"edge_error\" in c or \"edge_length\" in c:\n",
    "            if c not in to_keep:\n",
    "                to_drop.append(c)\n",
    "    df = df.drop(to_drop,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2590a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connections: ['01', '10', '12', '13', '21', '31', '35', '45', '53', '54', '56', '65']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>backend_name</th>\n",
       "      <th>N_qubtis</th>\n",
       "      <th>N_cx</th>\n",
       "      <th>cx_01</th>\n",
       "      <th>cx_02</th>\n",
       "      <th>cx_03</th>\n",
       "      <th>cx_04</th>\n",
       "      <th>cx_05</th>\n",
       "      <th>...</th>\n",
       "      <th>T1_6</th>\n",
       "      <th>T2_6</th>\n",
       "      <th>readout_error_6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-06 13:10:36-07:00</td>\n",
       "      <td>ibm_lagos</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.734718</td>\n",
       "      <td>92.600073</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-07-06 13:10:36-07:00</td>\n",
       "      <td>ibm_lagos</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.734718</td>\n",
       "      <td>92.600073</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-07-06 13:10:36-07:00</td>\n",
       "      <td>ibm_lagos</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.734718</td>\n",
       "      <td>92.600073</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-07-06 13:10:36-07:00</td>\n",
       "      <td>ibm_lagos</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.734718</td>\n",
       "      <td>92.600073</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-07-06 14:11:03-07:00</td>\n",
       "      <td>ibm_perth</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>234.956902</td>\n",
       "      <td>240.488458</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>8892</td>\n",
       "      <td>2023-07-19 14:53:52-07:00</td>\n",
       "      <td>ibm_perth</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.488154</td>\n",
       "      <td>313.822759</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>8893</td>\n",
       "      <td>2023-07-19 14:42:36-07:00</td>\n",
       "      <td>ibm_nairobi</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.585360</td>\n",
       "      <td>141.228784</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>8894</td>\n",
       "      <td>2023-06-07 15:11:48-07:00</td>\n",
       "      <td>ibm_lagos</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.383544</td>\n",
       "      <td>104.767721</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>8895</td>\n",
       "      <td>2023-06-07 14:34:17-07:00</td>\n",
       "      <td>ibm_perth</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.573329</td>\n",
       "      <td>244.762409</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>8896</td>\n",
       "      <td>2023-06-07 15:12:00-07:00</td>\n",
       "      <td>ibm_nairobi</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.353041</td>\n",
       "      <td>156.921626</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8897 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           last_update_date backend_name  N_qubtis  N_cx  \\\n",
       "0              0  2023-07-06 13:10:36-07:00    ibm_lagos         7    53   \n",
       "1              1  2023-07-06 13:10:36-07:00    ibm_lagos         7    40   \n",
       "2              2  2023-07-06 13:10:36-07:00    ibm_lagos         7    23   \n",
       "3              3  2023-07-06 13:10:36-07:00    ibm_lagos         7    37   \n",
       "4              4  2023-07-06 14:11:03-07:00    ibm_perth         7    73   \n",
       "...          ...                        ...          ...       ...   ...   \n",
       "8892        8892  2023-07-19 14:53:52-07:00    ibm_perth         7    18   \n",
       "8893        8893  2023-07-19 14:42:36-07:00  ibm_nairobi         7    48   \n",
       "8894        8894  2023-06-07 15:11:48-07:00    ibm_lagos         7    86   \n",
       "8895        8895  2023-06-07 14:34:17-07:00    ibm_perth         7    33   \n",
       "8896        8896  2023-06-07 15:12:00-07:00  ibm_nairobi         7    24   \n",
       "\n",
       "      cx_01  cx_02  cx_03  cx_04  cx_05  ...        T1_6        T2_6  \\\n",
       "0         6      0      0      0      0  ...   44.734718   92.600073   \n",
       "1         2      0      0      0      0  ...   44.734718   92.600073   \n",
       "2         2      0      0      0      0  ...   44.734718   92.600073   \n",
       "3         3      0      0      0      0  ...   44.734718   92.600073   \n",
       "4         4      0      0      0      0  ...  234.956902  240.488458   \n",
       "...     ...    ...    ...    ...    ...  ...         ...         ...   \n",
       "8892      7      0      0      0      0  ...  254.488154  313.822759   \n",
       "8893      4      0      0      0      0  ...  109.585360  141.228784   \n",
       "8894      7      0      0      0      0  ...  161.383544  104.767721   \n",
       "8895      2      0      0      0      0  ...  175.573329  244.762409   \n",
       "8896      8      0      0      0      0  ...  104.353041  156.921626   \n",
       "\n",
       "      readout_error_6  0  1  2  3  4  5  6  \n",
       "0              0.0137  2  1  0  3  4  5  6  \n",
       "1              0.0137  2  1  0  3  4  5  6  \n",
       "2              0.0137  0  1  2  3  4  5  6  \n",
       "3              0.0137  2  1  0  3  6  5  4  \n",
       "4              0.0090  0  1  2  3  4  5  6  \n",
       "...               ... .. .. .. .. .. .. ..  \n",
       "8892           0.0087  0  1  2  3  4  5  6  \n",
       "8893           0.0256  2  1  0  3  6  5  4  \n",
       "8894           0.0144  2  1  0  3  4  5  6  \n",
       "8895           0.0073  0  1  2  3  4  5  6  \n",
       "8896           0.0225  0  1  2  3  4  5  6  \n",
       "\n",
       "[8897 rows x 99 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qubits = 7\n",
    "# df = pd.read_csv(\"dataset/dataset_tesi/NN1_Dataset(\\uf03c=10Cx)_balanced1.csv\")\n",
    "df = pd.read_csv(\"dataset/dataset_tesi/NN1_Dataset(<=10Cx)_balanced1.csv\")\n",
    "\n",
    "data_to_use = int(1*len(df))\n",
    "df = df.iloc[:data_to_use]\n",
    "df = clear_dataset(df, num_qubits)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c843d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8897/8897 [00:06<00:00, 1321.77it/s]\n"
     ]
    }
   ],
   "source": [
    "last_num_qubits = len(df.columns)-num_qubits\n",
    "labels = df.iloc[:, last_num_qubits:].values\n",
    "\"\"\"\n",
    "Node fatures: T1, T2,readout_error (N*3)\n",
    "Edge features: CNOTs, edge_error, edge_length ((edges*3))\n",
    "edge_features -> ((t1_i,t2_i,readout_i),(t1_j,t2_j,readout_j),(edge_error_ij,edge_length_ij,cnot_ij))\n",
    "\n",
    "\"\"\"\n",
    "X,X_ev = [],[]\n",
    "for i in tqdm(range(len(df))):\n",
    "    edge_features = []\n",
    "    for edge_i in range(num_qubits):\n",
    "        for edge_j in range(num_qubits):\n",
    "            if edge_i != edge_j:\n",
    "                cx = df[\"cx_\"+str(edge_i)+str(edge_j)][i]\n",
    "                edge_error, edge_length  = 100000, 100000\n",
    "                if \"edge_error_\"+str(edge_i)+str(edge_j) in df.columns:\n",
    "                    edge_error = df[\"edge_error_\"+str(edge_i)+str(edge_j)][i]\n",
    "                    edge_length = df[\"edge_length_\"+str(edge_i)+str(edge_j)][i]\n",
    "                \n",
    "                t1_i = df[\"T1_\"+str(edge_i)][i]\n",
    "                t2_i = df[\"T2_\"+str(edge_i)][i]\n",
    "                readout_i = df[\"readout_error_\"+str(edge_i)][i]\n",
    "            \n",
    "                t1_j = df[\"T1_\"+str(edge_j)][i]\n",
    "                t2_j = df[\"T2_\"+str(edge_j)][i]\n",
    "                readout_j = df[\"readout_error_\"+str(edge_j)][i]\n",
    "                \n",
    "                \n",
    "                edge_features.append(np.array([t1_i,t2_i,readout_i,t1_j,t2_j,readout_j,cx,edge_error,edge_length]))\n",
    "    X.append(np.array(edge_features).flatten())\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9454d02c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8897, 378), (378,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "568963cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8897, 49)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_old =(df.iloc[:, last_num_qubits:].values)\n",
    "y = []\n",
    "for i in range(len(y_old)):\n",
    "    n = len(y_old[i])\n",
    "    y_new = np.array(([[0]*n]*n))\n",
    "    for j in range(len(y_old[i])):\n",
    "        y_new[j][y_old[i][j]] = 1\n",
    "    y_new = y_new.flatten()\n",
    "    y.append(y_new)\n",
    "    \n",
    "y=np.array(y)\n",
    "\n",
    "# y = np.array(y_old)\n",
    "y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed81b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:, 3:last_num_qubits].values\n",
    "SS = StandardScaler()\n",
    "X_st = SS.fit_transform(X)\n",
    "#MS = MinMaxScaler()\n",
    "#X_st = MS.fit_transform(X)\n",
    "\n",
    "#Building validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_st, y, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057b7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405e9c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 378)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 189)               71631     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 94)                17860     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                4655      \n",
      "=================================================================\n",
      "Total params: 94,146\n",
      "Trainable params: 94,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:17:24.304474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-24 15:17:24.329087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-24 15:17:24.329155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4090 computeCapability: 8.9\n",
      "coreClock: 2.595GHz coreCount: 128 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 938.86GiB/s\n",
      "2023-11-24 15:17:24.329224: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329248: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329268: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329287: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329306: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329322: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329342: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-24 15:17:24.329345: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-11-24 15:17:24.329730: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-11-24 15:17:24.332667: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3609600000 Hz\n",
      "2023-11-24 15:17:24.333092: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d94000b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-24 15:17:24.333099: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-24 15:17:24.333601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-24 15:17:24.333605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "        #d = 0.2\n",
    "        model = Sequential()\n",
    "        input_layer = Input(shape=input_shape, name='input')\n",
    "        layer1 = Dense(input_shape//2,kernel_initializer='uniform',activation='relu')(input_layer)\n",
    "        layer2 = Dense(input_shape//4,kernel_initializer='uniform',activation='relu')(layer1)\n",
    "        layer3 = Dense(49,kernel_initializer='uniform',activation='relu')(layer2)\n",
    "        merged = Model(inputs=[input_layer], outputs=[layer3])\n",
    "\n",
    "        return merged\n",
    "    \n",
    "    \n",
    "    \n",
    "def build_model_y_7(input_shape):\n",
    "        #d = 0.2\n",
    "        model = Sequential()\n",
    "        input_layer = Input(shape=input_shape, name='input')\n",
    "        layer1 = Dense(input_shape//2,kernel_initializer='uniform',activation='relu')(input_layer)\n",
    "        layer2 = Dense(input_shape//4,kernel_initializer='uniform',activation='relu')(layer1)\n",
    "        layer3 = Dense(input_shape//8,kernel_initializer='uniform',activation='relu')(layer2)\n",
    "        layer4 = Dense(input_shape//16,kernel_initializer='uniform',activation='relu')(layer3)\n",
    "        layer5 = Dense(7,kernel_initializer='uniform',activation='relu')(layer4)\n",
    "        merged = Model(inputs=[input_layer], outputs=[layer5])\n",
    "\n",
    "        return merged\n",
    "    \n",
    "def build_model_original_df(input_shape):\n",
    "        #d = 0.2\n",
    "        model = Sequential()\n",
    "        input_layer = Input(shape=input_shape, name='input')\n",
    "        layer1 = Dense(70,kernel_initializer='uniform',activation='relu')(input_layer)\n",
    "        layer2= Dense(49,kernel_initializer='uniform',activation='relu')(layer1)\n",
    "        merged = Model(inputs=[input_layer], outputs=[layer2])\n",
    "\n",
    "        return merged\n",
    "    \n",
    "def build_model_original_df_y_7(input_shape):\n",
    "        #d = 0.2\n",
    "        model = Sequential()\n",
    "        input_layer = Input(shape=input_shape, name='input')\n",
    "        layer1 = Dense(70,kernel_initializer='uniform',activation='relu')(input_layer)\n",
    "        layer2= Dense(49,kernel_initializer='uniform',activation='relu')(layer1)\n",
    "        layer3= Dense(25,kernel_initializer='uniform',activation='relu')(layer2)\n",
    "        layer4= Dense(12,kernel_initializer='uniform',activation='relu')(layer3)\n",
    "        layer5= Dense(7,kernel_initializer='uniform',activation='relu')(layer4)\n",
    "        \n",
    "        merged = Model(inputs=[input_layer], outputs=[layer5])\n",
    "\n",
    "        return merged\n",
    "\n",
    "model = build_model(X[0].shape[0])\n",
    "# model = build_model_y_7(X[0].shape[0])\n",
    "# model = build_model_original_df(X[0].shape[0])\n",
    "# model = build_model_original_df_y_7(X[0].shape[0])\n",
    "model.build(X[0].shape[0])\n",
    "# model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "# learning_rate = 0.01\n",
    "learning_rate = 0.0005\n",
    "optimizer = tf.optimizers.Adam(name='Adam', learning_rate=learning_rate)\n",
    "model.compile(\n",
    "  optimizer=optimizer,\n",
    "  loss='mean_squared_error',\n",
    "  metrics=[tf.keras.metrics.mean_squared_error])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47317ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape[0]//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad89a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1225 - mean_squared_error: 0.1225 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0595 - mean_squared_error: 0.0595 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0276 - val_mean_squared_error: 0.0276\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Time taken to train the model: 6.951971530914307\n",
      "dict_keys(['loss', 'mean_squared_error', 'val_loss', 'val_mean_squared_error'])\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    validation_split=0.15,\n",
    "    verbose=1)\n",
    "end = time.time()\n",
    "print(\"Time taken to train the model:\", end-start)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fefd6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.epoch, history.history['loss'] , label = \"loss\")\n",
    "plt.plot(history.epoch, history.history['val_loss'] , label = \"val_loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931fa21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8dbb13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in range(len(train_pred)):\n",
    "#     actual=y_train[i].tolist()\n",
    "#     predicted=np.round(train_pred[i]).astype(int).tolist()\n",
    "#     print(actual,predicted)\n",
    "#     if actual == predicted:\n",
    "#         count = count + 1\n",
    "        \n",
    "# print(\"Train accuracy:\",count/len(train_pred))\n",
    "\n",
    "# count = 0\n",
    "# for i in range(len(test_pred)):\n",
    "#     actual=y_test[i].tolist()\n",
    "#     predicted=np.round(test_pred[i]).astype(int).tolist()\n",
    "#     if actual == predicted:\n",
    "#         count = count + 1\n",
    "        \n",
    "# print(\"Test accuracy:\",count/len(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8dd7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b188ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        if i!=j:\n",
    "            x.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a75b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9e0248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9069564131385038\n"
     ]
    }
   ],
   "source": [
    "def get_labels(y):\n",
    "    labels = []\n",
    "    for i in range(len(y)):\n",
    "        labels.append(np.where(y[i]==np.max(y[i]))[0][0])\n",
    "#         for j in range(len(y[i])):\n",
    "#             if y[i][j] != 0:\n",
    "#                 labels.append(j)\n",
    "                \n",
    "    return labels\n",
    "\n",
    "count = 0\n",
    "for i in range(len(train_pred)):\n",
    "    actual=get_labels(np.reshape(y_train[i],(7,7)))\n",
    "    predicted=get_labels(np.reshape(train_pred[i],(7,7)))\n",
    "#     print(actual)\n",
    "#     print(predicted)\n",
    "#     print(\"---------------------------\")\n",
    "    if actual == predicted:\n",
    "        count = count + 1\n",
    "        \n",
    "print(\"Train accuracy:\",count/len(train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1354bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8910112359550562\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(test_pred)):\n",
    "    actual=get_labels(np.reshape(y_test[i],(7,7)))\n",
    "    predicted=get_labels(np.reshape(test_pred[i],(7,7)))\n",
    "#     print(actual)\n",
    "#     print(predicted)\n",
    "#     print(\"---------------------------\")\n",
    "    if actual == predicted:\n",
    "        count = count + 1\n",
    "        \n",
    "print(\"Test accuracy:\",count/len(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb0c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea630d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "378 features\n",
    "Train accuracy: 0.9030848007993006\n",
    "Test accuracy: 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "89 features\n",
    "Train accuracy: 0.8582490320969152\n",
    "Test accuracy: 0.8674157303370786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7604c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ab85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9d84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2a418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65bc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a03db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da7fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dnn_for_qubit_mapping]",
   "language": "python",
   "name": "conda-env-dnn_for_qubit_mapping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
